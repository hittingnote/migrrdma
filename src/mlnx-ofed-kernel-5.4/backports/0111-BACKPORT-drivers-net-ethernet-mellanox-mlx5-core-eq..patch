From: Shay Drory <shayd@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/eq.c

Change-Id: Ib397043647c4c87ccd7462d99bc4b715f373393f
---
 drivers/net/ethernet/mellanox/mlx5/core/eq.c | 34 ++++++++++++++++++--
 1 file changed, 32 insertions(+), 2 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -43,7 +43,9 @@ enum {
 	MLX5_EQ_POLLING_BUDGET	= 128,
 };
 
+#ifdef HAVE_STATIC_ASSERT
 static_assert(MLX5_EQ_POLLING_BUDGET <= MLX5_NUM_SPARE_EQE);
+#endif
 
 struct mlx5_eq_table {
 	struct list_head        comp_eqs_list;
@@ -123,7 +125,11 @@ static int mlx5_eq_comp_int(struct notif
 		/* Make sure we read EQ entry contents after we've
 		 * checked the ownership bit.
 		 */
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 		/* Assume (eqe->type) is always MLX5_EVENT_TYPE_COMP */
 		cqn = be32_to_cpu(eqe->data.comp.cqn) & 0xffffff;
 
@@ -200,7 +206,7 @@ static int mlx5_eq_async_int(struct noti
 	struct mlx5_eq_table *eqt;
 	struct mlx5_core_dev *dev;
 	struct mlx5_eqe *eqe;
-	unsigned long flags;
+	unsigned long flags = 0;
 	int num_eqes = 0;
 
 	dev = eq->dev;
@@ -217,7 +223,11 @@ static int mlx5_eq_async_int(struct noti
 		 * Make sure we read EQ entry contents after we've
 		 * checked the ownership bit.
 		 */
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 
 		atomic_notifier_call_chain(&eqt->nh[eqe->type], eqe->type, eqe);
 		atomic_notifier_call_chain(&eqt->nh[MLX5_EVENT_TYPE_NOTIFY_ANY], eqe->type, eqe);
@@ -321,7 +331,11 @@ create_map_eq(struct mlx5_core_dev *dev,
 
 	eq->vecidx = vecidx;
 	eq->eqn = MLX5_GET(create_eq_out, out, eq_number);
-	eq->irqn = pci_irq_vector(dev->pdev, vecidx);
+#ifdef HAVE_PCI_IRQ_API
+       eq->irqn = pci_irq_vector(dev->pdev, vecidx);
+#else
+	eq->irqn = mlx5_get_msix_vec(dev, vecidx);
+#endif
 	eq->dev = dev;
 	eq->doorbell = priv->uar->map + MLX5_EQ_DOORBEL_OFFSET;
 
@@ -816,7 +830,11 @@ struct mlx5_eqe *mlx5_eq_get_eqe(struct
 	 * checked the ownership bit.
 	 */
 	if (eqe)
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 
 	return eqe;
 }
@@ -1037,8 +1055,13 @@ static int set_rmap(struct mlx5_core_dev
 	vecidx = MLX5_IRQ_VEC_COMP_BASE;
 	for (; vecidx < eq_table->num_comp_eqs + MLX5_IRQ_VEC_COMP_BASE;
 	     vecidx++) {
+#ifdef HAVE_PCI_IRQ_API
 		err = irq_cpu_rmap_add(eq_table->rmap,
 				       pci_irq_vector(mdev->pdev, vecidx));
+#else
+		err = irq_cpu_rmap_add(eq_table->rmap,
+				       mdev->priv.msix_arr[vecidx].vector);
+#endif
 		if (err) {
 			mlx5_core_err(mdev, "irq_cpu_rmap_add failed. err %d",
 				      err);
@@ -1054,6 +1077,13 @@ err_out:
 	return err;
 }
 
+#ifndef HAVE_PCI_IRQ_API
+u32 mlx5_get_msix_vec(struct mlx5_core_dev *dev, int vecidx)
+{
+	return dev->priv.msix_arr[vecidx].vector;
+}
+#endif
+
 /* This function should only be called after mlx5_cmd_force_teardown_hca */
 void mlx5_core_eq_free_irqs(struct mlx5_core_dev *dev)
 {
